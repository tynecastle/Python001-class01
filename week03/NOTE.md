1. Scrapy并发参数优化原理
- 最大并发请求数量(CONCURRENT_REQUESTS)：默认是16，不能使用太大的值，防止目标网站或爬虫本地服务器负载过高
- 下载延时(DOWNLOAD_DELAY)：两批并发请求之间的等待时间，防止下载过快导致IP被目标网站的反爬虫系统封禁
- Scrapy的底层引擎是基于Twisted的异步IO框架编写的
- Twisted是异步编程模型，任务时间互相独立，用于大量I/O密集型的操作
2. 多进程的创建
- 多进程、多线程、协程的目的都是希望尽可能多地处理任务
- 产生新进程的两种方式：
  - os.fork()  # 底层模块，可以用来研究Linux/Mac创建进程的底层原理
  - multiprocessing.Process()  # 高级的封装，把底层的功能都封装好了
- 多进程的第一个问题：进程的父子关系
  - fork()一旦运行就会创建一条新的进程，两个进程会一起执行
  - fork()运行时会有2个返回值：返回值大于0时，此进程为父进程，且返回值为子进程的PID；返回值为0时，此进程为子进程
  - multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs={})
    - group：分组，实际上很少使用
    - target：表示可调用对象，传入方法的名字，不能加括号
    - name：别名，相当于给这个进程取一个名字
    - args：表示被调用对象的位置参数元组，比如target是函数a，他有两个参数m，n，那么args就传入(m, n)即可
    - kwargs：表示调用对象的字典
    - join([timeout])表示合并子进程，父进程会等待子进程执行结束
    - 如果可选参数timeout是None（默认值），则该方法将阻塞，直到调用join()方法的进程终止
    - 如果timeout是一个正数，它最多会阻塞timeout秒
    - 如果进程终止或方法超时，则该方法返回None
    - 检查进程的exitcode以确定它是否终止
    - 一个进程可以合并多次。
    - 进程无法并入自身，会导致死锁
    - join()必须在start()后面执行，尝试在启动进程之前合并进程是错误的
3. 多进程程序调试技巧